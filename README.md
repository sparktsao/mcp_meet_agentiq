# When MCP is Boosted by NVIDIA AgentIQ and NIM's Super Power âš¡ğŸ§ 

This project is an advanced AI-powered application that integrates multiple cutting-edge technologies to create a more dynamic, context-aware, and powerful conversational experience.

## ğŸš€ Overview

At the core of this stack is **Anthropic MCP (via FastMCP)** and **GPT-4o-mini**, orchestrated with **LangGraph**, and presented via a **Streamlit frontend**. We've supercharged it with **NVIDIA's AgentIQ Workflow** and **NIM Inference Microservice**, bringing in the power of reasoning with **NVIDIAâ€™s Llama3 Nemotron Super 49B** model (R1 version).

### ğŸ”Œ Tech Stack

- **ğŸ§  NVIDIA AgentIQ** â€“ Agentic workflow framework with tool-use capabilities
- **ğŸ“¦ NVIDIA NIM** â€“ Model deployment and inference microservice
- **ğŸ¦™ NVIDIA Llama3 49B R1** â€“ `nvidia/llama-3_3-nemotron-super-49b-v1`
- **ğŸ¤– Anthropic MCP** â€“ Powered by FastMCP
- **ğŸ”„ GPT-4o-mini** â€“ As the orchestration model
- **ğŸ”— LangGraph** â€“ Graph-based LLM orchestration for tool-calling agents
- **ğŸŒ Streamlit** â€“ For interactive frontend UI
- **ğŸ“ˆ LangFuse** â€“ Monitoring and observability for LLM apps

---

## ğŸ’¡ Features

- Natural and dynamic reasoning with large-scale NVIDIA models
- Tool-using agents enabled by LangGraph and AgentIQ
- Lightweight frontend for chat interaction
- Easy deployment using `aiq` CLI
- Real-time LLM monitoring and observability with LangFuse

---

## âš™ï¸ Setup & Usage

1. **Run AgentIQ Workflow**
   ```bash
   aiq run --config_file workflow.yaml --input "List five subspecies of Aardvarks"
